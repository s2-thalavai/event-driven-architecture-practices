# production-grade event-driven system

let‚Äôs build a **small but production-grade** event-driven system with:

-   **Kafka** as the event broker
    
-   **Python** producer/consumer (Order + Payment services)
    
-   **Docker Compose** to run everything
    

## 1. Project structure

```
event-system/
‚îú‚îÄ docker-compose.yml
‚îú‚îÄ producer/          # Order Service
‚îÇ  ‚îú‚îÄ Dockerfile
‚îÇ  ‚îú‚îÄ requirements.txt
‚îÇ  ‚îî‚îÄ app.py
‚îî‚îÄ consumer/          # Payment Service
   ‚îú‚îÄ Dockerfile
   ‚îú‚îÄ requirements.txt
   ‚îî‚îÄ app.py
``` 

> We‚Äôll use **JSON events** on a topic `orders` and a **DLQ** topic `orders.dlq`.

## 2. docker-compose.yml

``` yaml
version: "3.8"

services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000

  kafka:
    image: confluentinc/cp-kafka:7.5.0
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"          # external
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_INTERNAL:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092,PLAINTEXT_INTERNAL://kafka:29092
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,PLAINTEXT_INTERNAL://0.0.0.0:29092
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT_INTERNAL
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"  # For demo only; in real prod you‚Äôd manage topics explicitly.

  order-producer:
    build: ./producer
    depends_on:
      - kafka
    environment:
      BOOTSTRAP_SERVERS: kafka:29092
      ORDERS_TOPIC: orders

  payment-consumer:
    build: ./consumer
    depends_on:
      - kafka
    environment:
      BOOTSTRAP_SERVERS: kafka:29092
      ORDERS_TOPIC: orders
      DLQ_TOPIC: orders.dlq
      GROUP_ID: payment-service

```

## 3. Producer service (Order Service)

### producer/requirements.txt

```confluent-kafka==2.5.0``` 

### producer/Dockerfile

``` dockerfile
FROM python:3.12-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY app.py .

CMD ["python", "app.py"]

```

### producer/app.py

This simulates an Order Service that emits idempotent events to Kafka.

``` python
import json
import os
import signal
import sys
import time
import uuid
from datetime import datetime, timezone

from confluent_kafka import Producer

BOOTSTRAP_SERVERS = os.getenv("BOOTSTRAP_SERVERS", "kafka:29092")
ORDERS_TOPIC = os.getenv("ORDERS_TOPIC", "orders")


running = True


def handle_shutdown(signum, frame):
    global running
    print("Order Service: shutting down‚Ä¶")
    running = False


signal.signal(signal.SIGINT, handle_shutdown)
signal.signal(signal.SIGTERM, handle_shutdown)


def create_producer() -> Producer:
    config = {
        "bootstrap.servers": BOOTSTRAP_SERVERS,
        "client.id": "order-service",
        # Production-ish settings:
        "enable.idempotence": True,
        "acks": "all",
        "retries": 10,
        "linger.ms": 5,
        "batch.num.messages": 1000,
    }
    return Producer(config)


def delivery_report(err, msg):
    if err is not None:
        print(f"Delivery failed for record {msg.key()}: {err}")
    else:
        print(
            f"Record produced to {msg.topic()} "
            f"[partition {msg.partition()} @ offset {msg.offset()}]"
        )


def build_order_event() -> dict:
    order_id = str(uuid.uuid4())
    user_id = f"user-{uuid.uuid4().hex[:8]}"
    amount = round(10 + 90 * (uuid.uuid4().int % 100) / 100, 2)

    return {
        "event_type": "OrderPlaced",
        "event_version": 1,
        "order_id": order_id,
        "user_id": user_id,
        "amount": amount,
        "currency": "USD",
        "created_at": datetime.now(timezone.utc).isoformat(),
    }


def main():
    producer = create_producer()

    print(f"Order Service: producing to topic '{ORDERS_TOPIC}' on {BOOTSTRAP_SERVERS}")
    try:
        while running:
            event = build_order_event()
            key = event["order_id"].encode("utf-8")
            value = json.dumps(event).encode("utf-8")

            try:
                producer.produce(
                    topic=ORDERS_TOPIC,
                    key=key,
                    value=value,
                    on_delivery=delivery_report,
                )
            except BufferError as e:
                # Local buffer full, flush and retry
                print(f"Local producer queue is full ({e}), flushing‚Ä¶")
                producer.flush()

            # Poll to trigger delivery callbacks
            producer.poll(0)

            time.sleep(2)  # simulate incoming orders

    finally:
        print("Order Service: flushing producer‚Ä¶")
        producer.flush(10)
        print("Order Service: exit.")
        sys.exit(0)


if __name__ == "__main__":
    main()

```

## 4. Consumer service (Payment Service + DLQ)

### consumer/requirements.txt

```confluent-kafka==2.5.0``` 

### consumer/Dockerfile

``` dockerfile
FROM python:3.12-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY app.py .

CMD ["python", "app.py"]

```

### consumer/app.py

This simulates a **Payment Service**:

-   Consumes `orders` in a **consumer group**
    
-   Processes each message
    
-   On repeated failures, sends the original event to a **DLQ topic** `orders.dlq`
    
-   Commits offsets manually after success

``` python
import json
import os
import random
import signal
import sys
import time
from datetime import datetime, timezone

from confluent_kafka import Consumer, Producer, KafkaError

BOOTSTRAP_SERVERS = os.getenv("BOOTSTRAP_SERVERS", "kafka:29092")
ORDERS_TOPIC = os.getenv("ORDERS_TOPIC", "orders")
DLQ_TOPIC = os.getenv("DLQ_TOPIC", "orders.dlq")
GROUP_ID = os.getenv("GROUP_ID", "payment-service")

MAX_PROCESSING_RETRIES = 3
running = True


def handle_shutdown(signum, frame):
    global running
    print("Payment Service: shutting down‚Ä¶")
    running = False


signal.signal(signal.SIGINT, handle_shutdown)
signal.signal(signal.SIGTERM, handle_shutdown)


def create_consumer() -> Consumer:
    config = {
        "bootstrap.servers": BOOTSTRAP_SERVERS,
        "group.id": GROUP_ID,
        "enable.auto.commit": False,  # manual commit
        "auto.offset.reset": "earliest",
    }
    return Consumer(config)


def create_dlq_producer() -> Producer:
    return Producer(
        {
            "bootstrap.servers": BOOTSTRAP_SERVERS,
            "client.id": "payment-service-dlq-producer",
            "acks": "all",
        }
    )


def process_payment(event: dict):
    """
    Simulate payment processing.
    In real life this would be idempotent (e.g., using order_id as key)
    and talk to an external payment gateway.
    """
    order_id = event["order_id"]
    amount = event["amount"]

    # simulate intermittent failure ~20% of the time
    if random.random() < 0.2:
        raise RuntimeError(f"Random failure processing order {order_id}")

    print(
        f"[PAYMENT] Successfully processed payment for order {order_id} "
        f"amount={amount} {event.get('currency','')}"
    )


def send_to_dlq(dlq_producer: Producer, msg, error_reason: str):
    payload = {
        "original_topic": msg.topic(),
        "original_partition": msg.partition(),
        "original_offset": msg.offset(),
        "key": msg.key().decode("utf-8") if msg.key() else None,
        "value": msg.value().decode("utf-8") if msg.value() else None,
        "error_reason": error_reason,
        "failed_at": datetime.now(timezone.utc).isoformat(),
    }

    dlq_producer.produce(
        topic=DLQ_TOPIC,
        key=payload["key"].encode("utf-8") if payload["key"] else None,
        value=json.dumps(payload).encode("utf-8"),
    )
    dlq_producer.flush(5)
    print(f"[DLQ] Sent message for key={payload['key']} to {DLQ_TOPIC}")


def main():
    consumer = create_consumer()
    dlq_producer = create_dlq_producer()

    consumer.subscribe([ORDERS_TOPIC])
    print(
        f"Payment Service: consuming from '{ORDERS_TOPIC}' as group '{GROUP_ID}'"
    )

    try:
        while running:
            msg = consumer.poll(1.0)
            if msg is None:
                continue

            if msg.error():
                if msg.error().code() == KafkaError._PARTITION_EOF:
                    continue
                print(f"Consumer error: {msg.error()}")
                continue

            key = msg.key().decode("utf-8") if msg.key() else None
            raw_value = msg.value().decode("utf-8")

            try:
                event = json.loads(raw_value)
            except json.JSONDecodeError as e:
                print(f"Invalid JSON, sending to DLQ: {e}")
                send_to_dlq(dlq_producer, msg, "Invalid JSON")
                consumer.commit(message=msg)
                continue

            # basic retry loop around processing
            attempts = 0
            while attempts < MAX_PROCESSING_RETRIES:
                try:
                    process_payment(event)
                    consumer.commit(message=msg)  # commit only on success
                    break
                except Exception as e:
                    attempts += 1
                    print(
                        f"[ERROR] Failed to process order_id={event.get('order_id')} "
                        f"attempt={attempts}/{MAX_PROCESSING_RETRIES}: {e}"
                    )
                    time.sleep(1)

            if attempts >= MAX_PROCESSING_RETRIES:
                print(
                    f"[ERROR] Max retries exceeded, sending order_id={event.get('order_id')} to DLQ"
                )
                send_to_dlq(dlq_producer, msg, "Max processing retries exceeded")
                consumer.commit(message=msg)

    finally:
        print("Payment Service: closing consumer‚Ä¶")
        consumer.close()
        print("Payment Service: exit.")
        sys.exit(0)


if __name__ == "__main__":
    main()

```
-------

## 5. Running it

From the project root:

`docker compose up --build` 

You should see:

-   `order-producer` printing delivery logs to `orders`
    
-   `payment-consumer` printing `[PAYMENT] Successfully processed‚Ä¶`
    
-   Occasional failures being retried, and some messages routed to `orders.dlq`


## 6. How this leans toward ‚Äúproduction-grade‚Äù

-   **Idempotent producer** (`enable.idempotence`, `acks=all`, retries)
    
-   **Consumer group** with manual commits for at-least-once semantics
    
-   **DLQ topic** for failed messages after retries
    
-   **Graceful shutdown** via `SIGINT`/`SIGTERM`
    
-   **Structured JSON events** with versioning (`event_version`)
    
-   **Config via environment variables** (good for Kubernetes later)

-----

## Add OpenTelemetry tracing + logging

1.  Add an **OTel Collector** + **Jaeger** to `docker-compose.yml`
    
2.  Instrument both **Order Service (producer)** and **Payment Service (consumer)** with:
    
    -   Traces (`TracerProvider`, spans)
        
    -   Logs (`LoggingHandler` + JSON-ish format)
        
    -   Kafka exporter via **OTLP ‚Üí Collector ‚Üí Jaeger**
        

### 1Ô∏è. Update docker-compose.yml

Add otel-collector and jaeger services, and pass OTEL configs to apps.

``` yaml
version: "3.8"

services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000

  kafka:
    image: confluentinc/cp-kafka:7.5.0
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_INTERNAL:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092,PLAINTEXT_INTERNAL://kafka:29092
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,PLAINTEXT_INTERNAL://0.0.0.0:29092
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT_INTERNAL
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"

  # OpenTelemetry Collector
  otel-collector:
    image: otel/opentelemetry-collector-contrib:0.110.0
    command: ["--config=/etc/otel-collector-config.yml"]
    volumes:
      - ./otel-collector-config.yml:/etc/otel-collector-config.yml
    ports:
      - "4317:4317"   # OTLP gRPC
      - "4318:4318"   # OTLP HTTP

  # Jaeger for tracing UI
  jaeger:
    image: jaegertracing/all-in-one:1.63
    depends_on:
      - otel-collector
    environment:
      COLLECTOR_OTLP_ENABLED: "true"
    ports:
      - "16686:16686"     # UI

  order-producer:
    build: ./producer
    depends_on:
      - kafka
      - otel-collector
    environment:
      BOOTSTRAP_SERVERS: kafka:29092
      ORDERS_TOPIC: orders
      OTEL_SERVICE_NAME: order-service
      OTEL_EXPORTER_OTLP_ENDPOINT: http://otel-collector:4317
      OTEL_EXPORTER_OTLP_PROTOCOL: grpc

  payment-consumer:
    build: ./consumer
    depends_on:
      - kafka
      - otel-collector
    environment:
      BOOTSTRAP_SERVERS: kafka:29092
      ORDERS_TOPIC: orders
      DLQ_TOPIC: orders.dlq
      GROUP_ID: payment-service
      OTEL_SERVICE_NAME: payment-service
      OTEL_EXPORTER_OTLP_ENDPOINT: http://otel-collector:4317
      OTEL_EXPORTER_OTLP_PROTOCOL: grpc

```

### 2Ô∏è. Add otel-collector-config.yml (root folder)

``` yaml

receivers:
  otlp:
    protocols:
      grpc:
      http:

exporters:
  jaeger:
    endpoint: jaeger:14250
    tls:
      insecure: true

processors:
  batch:

service:
  pipelines:
    traces:
      receivers: [otlp]
      processors: [batch]
      exporters: [jaeger]

```

> Now traces from both services (via OTLP) will show up in Jaeger at
> http://localhost:16686

## 3Ô∏è. Instrument the Order Service (producer)

producer/requirements.txt (extended)

``` text
confluent-kafka==2.5.0
opentelemetry-sdk==1.27.0
opentelemetry-api==1.27.0
opentelemetry-exporter-otlp==1.27.0
```

### producer/app.py (full, with tracing + logging)

``` python

import json
import logging
import os
import signal
import sys
import time
import uuid
from datetime import datetime, timezone

from confluent_kafka import Producer

from opentelemetry import trace
from opentelemetry.exporter.otlp.proto.grpc.trace_exporter import OTLPSpanExporter
from opentelemetry.sdk.resources import Resource
from opentelemetry.sdk.trace import TracerProvider
from opentelemetry.sdk.trace.export import BatchSpanProcessor

BOOTSTRAP_SERVERS = os.getenv("BOOTSTRAP_SERVERS", "kafka:29092")
ORDERS_TOPIC = os.getenv("ORDERS_TOPIC", "orders")

OTEL_SERVICE_NAME = os.getenv("OTEL_SERVICE_NAME", "order-service")
OTEL_EXPORTER_OTLP_ENDPOINT = os.getenv(
    "OTEL_EXPORTER_OTLP_ENDPOINT", "http://otel-collector:4317"
)

running = True

# ---------- Logging setup ----------

logger = logging.getLogger("order-service")
logger.setLevel(logging.INFO)

handler = logging.StreamHandler(sys.stdout)
handler.setFormatter(
    logging.Formatter(
        fmt="%(asctime)s | %(name)s | %(levelname)s | %(message)s",
        datefmt="%Y-%m-%dT%H:%M:%S%z",
    )
)
logger.addHandler(handler)

# ---------- OpenTelemetry setup ----------

resource = Resource.create({"service.name": OTEL_SERVICE_NAME})

trace_provider = TracerProvider(resource=resource)
span_exporter = OTLPSpanExporter(endpoint=OTEL_EXPORTER_OTLP_ENDPOINT, insecure=True)
span_processor = BatchSpanProcessor(span_exporter)
trace_provider.add_span_processor(span_processor)
trace.set_tracer_provider(trace_provider)

tracer = trace.get_tracer(__name__)


def handle_shutdown(signum, frame):
    global running
    logger.info("Order Service: shutting down‚Ä¶")
    running = False


signal.signal(signal.SIGINT, handle_shutdown)
signal.signal(signal.SIGTERM, handle_shutdown)


def create_producer() -> Producer:
    config = {
        "bootstrap.servers": BOOTSTRAP_SERVERS,
        "client.id": "order-service",
        "enable.idempotence": True,
        "acks": "all",
        "retries": 10,
        "linger.ms": 5,
        "batch.num.messages": 1000,
    }
    return Producer(config)


def delivery_report(err, msg):
    if err is not None:
        logger.error(
            "Delivery failed",
            extra={"key": msg.key(), "topic": msg.topic(), "error": str(err)},
        )
    else:
        logger.info(
            "Record produced",
            extra={
                "topic": msg.topic(),
                "partition": msg.partition(),
                "offset": msg.offset(),
            },
        )


def build_order_event() -> dict:
    order_id = str(uuid.uuid4())
    user_id = f"user-{uuid.uuid4().hex[:8]}"
    amount = round(10 + 90 * (uuid.uuid4().int % 100) / 100, 2)

    return {
        "event_type": "OrderPlaced",
        "event_version": 1,
        "order_id": order_id,
        "user_id": user_id,
        "amount": amount,
        "currency": "USD",
        "created_at": datetime.now(timezone.utc).isoformat(),
    }


def main():
    producer = create_producer()

    logger.info(
        "Order Service started",
        extra={"topic": ORDERS_TOPIC, "bootstrap_servers": BOOTSTRAP_SERVERS},
    )

    try:
        while running:
            event = build_order_event()

            # Create a span for publishing the order
            with tracer.start_as_current_span("publish_order") as span:
                span.set_attribute("messaging.system", "kafka")
                span.set_attribute("messaging.destination", ORDERS_TOPIC)
                span.set_attribute("order.id", event["order_id"])
                span.set_attribute("user.id", event["user_id"])
                span.set_attribute("amount", event["amount"])

                key = event["order_id"].encode("utf-8")
                value = json.dumps(event).encode("utf-8")

                try:
                    producer.produce(
                        topic=ORDERS_TOPIC,
                        key=key,
                        value=value,
                        on_delivery=delivery_report,
                    )
                    logger.info(
                        "Order event produced",
                        extra={
                            "order_id": event["order_id"],
                            "user_id": event["user_id"],
                            "amount": event["amount"],
                        },
                    )
                except BufferError as e:
                    logger.warning(
                        "Local producer queue is full; flushing",
                        extra={"error": str(e)},
                    )
                    producer.flush()

                producer.poll(0)

            time.sleep(2)

    finally:
        logger.info("Flushing producer‚Ä¶")
        producer.flush(10)
        logger.info("Order Service exit.")
        trace_provider.shutdown()
        sys.exit(0)


if __name__ == "__main__":
    main()

```


## 4Ô∏è. Instrument the Payment Service (consumer)

### consumer/requirements.txt

```
confluent-kafka==2.5.0
opentelemetry-sdk==1.27.0
opentelemetry-api==1.27.0
opentelemetry-exporter-otlp==1.27.0
``` 

### consumer/app.py (full, with tracing + logging)

``` python
import json
import logging
import os
import random
import signal
import sys
import time
from datetime import datetime, timezone

from confluent_kafka import Consumer, Producer, KafkaError

from opentelemetry import trace
from opentelemetry.exporter.otlp.proto.grpc.trace_exporter import OTLPSpanExporter
from opentelemetry.sdk.resources import Resource
from opentelemetry.sdk.trace import TracerProvider
from opentelemetry.sdk.trace.export import BatchSpanProcessor

BOOTSTRAP_SERVERS = os.getenv("BOOTSTRAP_SERVERS", "kafka:29092")
ORDERS_TOPIC = os.getenv("ORDERS_TOPIC", "orders")
DLQ_TOPIC = os.getenv("DLQ_TOPIC", "orders.dlq")
GROUP_ID = os.getenv("GROUP_ID", "payment-service")

OTEL_SERVICE_NAME = os.getenv("OTEL_SERVICE_NAME", "payment-service")
OTEL_EXPORTER_OTLP_ENDPOINT = os.getenv(
    "OTEL_EXPORTER_OTLP_ENDPOINT", "http://otel-collector:4317"
)

MAX_PROCESSING_RETRIES = 3
running = True

# ---------- Logging ----------

logger = logging.getLogger("payment-service")
logger.setLevel(logging.INFO)

handler = logging.StreamHandler(sys.stdout)
handler.setFormatter(
    logging.Formatter(
        fmt="%(asctime)s | %(name)s | %(levelname)s | %(message)s",
        datefmt="%Y-%m-%dT%H:%M:%S%z",
    )
)
logger.addHandler(handler)

# ---------- OpenTelemetry ----------

resource = Resource.create({"service.name": OTEL_SERVICE_NAME})

trace_provider = TracerProvider(resource=resource)
span_exporter = OTLPSpanExporter(endpoint=OTEL_EXPORTER_OTLP_ENDPOINT, insecure=True)
span_processor = BatchSpanProcessor(span_exporter)
trace_provider.add_span_processor(span_processor)
trace.set_tracer_provider(trace_provider)

tracer = trace.get_tracer(__name__)


def handle_shutdown(signum, frame):
    global running
    logger.info("Payment Service: shutting down‚Ä¶")
    running = False


signal.signal(signal.SIGINT, handle_shutdown)
signal.signal(signal.SIGTERM, handle_shutdown)


def create_consumer() -> Consumer:
    config = {
        "bootstrap.servers": BOOTSTRAP_SERVERS,
        "group.id": GROUP_ID,
        "enable.auto.commit": False,
        "auto.offset.reset": "earliest",
    }
    return Consumer(config)


def create_dlq_producer() -> Producer:
    return Producer(
        {
            "bootstrap.servers": BOOTSTRAP_SERVERS,
            "client.id": "payment-service-dlq-producer",
            "acks": "all",
        }
    )


def process_payment(event: dict):
    order_id = event["order_id"]
    amount = event["amount"]

    # Simulate 20% random failure
    if random.random() < 0.2:
        raise RuntimeError(f"Random failure processing order {order_id}")

    logger.info(
        "[PAYMENT] Payment processed",
        extra={"order_id": order_id, "amount": amount, "currency": event.get("currency")},
    )


def send_to_dlq(dlq_producer: Producer, msg, error_reason: str):
    payload = {
        "original_topic": msg.topic(),
        "original_partition": msg.partition(),
        "original_offset": msg.offset(),
        "key": msg.key().decode("utf-8") if msg.key() else None,
        "value": msg.value().decode("utf-8") if msg.value() else None,
        "error_reason": error_reason,
        "failed_at": datetime.now(timezone.utc).isoformat(),
    }

    dlq_producer.produce(
        topic=DLQ_TOPIC,
        key=payload["key"].encode("utf-8") if payload["key"] else None,
        value=json.dumps(payload).encode("utf-8"),
    )
    dlq_producer.flush(5)
    logger.warning(
        "[DLQ] Message sent to DLQ",
        extra={"dlq_topic": DLQ_TOPIC, "key": payload["key"], "reason": error_reason},
    )


def main():
    consumer = create_consumer()
    dlq_producer = create_dlq_producer()

    consumer.subscribe([ORDERS_TOPIC])
    logger.info(
        "Payment Service started",
        extra={
            "orders_topic": ORDERS_TOPIC,
            "group_id": GROUP_ID,
            "bootstrap_servers": BOOTSTRAP_SERVERS,
        },
    )

    try:
        while running:
            msg = consumer.poll(1.0)
            if msg is None:
                continue

            if msg.error():
                if msg.error().code() == KafkaError._PARTITION_EOF:
                    continue
                logger.error("Consumer error", extra={"error": str(msg.error())})
                continue

            key = msg.key().decode("utf-8") if msg.key() else None
            raw_value = msg.value().decode("utf-8")

            # span around "consume + process"
            with tracer.start_as_current_span("consume_order") as span:
                span.set_attribute("messaging.system", "kafka")
                span.set_attribute("messaging.destination", ORDERS_TOPIC)
                span.set_attribute("messaging.kafka.partition", msg.partition())
                span.set_attribute("messaging.kafka.offset", msg.offset())
                if key:
                    span.set_attribute("messaging.kafka.key", key)

                try:
                    event = json.loads(raw_value)
                except json.JSONDecodeError as e:
                    logger.error(
                        "Invalid JSON, sending to DLQ",
                        extra={"error": str(e), "raw": raw_value},
                    )
                    send_to_dlq(dlq_producer, msg, "Invalid JSON")
                    consumer.commit(message=msg)
                    continue

                # add business attributes to span
                span.set_attribute("order.id", event.get("order_id"))
                span.set_attribute("user.id", event.get("user_id"))
                span.set_attribute("amount", event.get("amount"))

                attempts = 0
                while attempts < MAX_PROCESSING_RETRIES:
                    try:
                        process_payment(event)
                        consumer.commit(message=msg)
                        break
                    except Exception as e:
                        attempts += 1
                        logger.error(
                            "Failed to process payment",
                            extra={
                                "order_id": event.get("order_id"),
                                "attempt": attempts,
                                "max_attempts": MAX_PROCESSING_RETRIES,
                                "error": str(e),
                            },
                        )
                        span.record_exception(e)
                        span.set_attribute("retry.attempt", attempts)
                        time.sleep(1)

                if attempts >= MAX_PROCESSING_RETRIES:
                    logger.error(
                        "Max retries exceeded, sending to DLQ",
                        extra={"order_id": event.get("order_id")},
                    )
                    send_to_dlq(
                        dlq_producer,
                        msg,
                        "Max processing retries exceeded",
                    )
                    consumer.commit(message=msg)

    finally:
        logger.info("Payment Service: closing consumer‚Ä¶")
        consumer.close()
        trace_provider.shutdown()
        logger.info("Payment Service exit.")
        sys.exit(0)


if __name__ == "__main__":
    main()
```


## 5Ô∏è. Running and viewing traces

From the project root:

`docker compose up --build` 

Then open **Jaeger UI** in your browser:

-   URL: `http://localhost:16686`
    
-   Choose service: `order-service` or `payment-service`
    
-   You‚Äôll see spans like `publish_order` and `consume_order` with attributes:
    
    -   `messaging.system = kafka`
        
    -   `messaging.destination = orders`
        
    -   `order.id`, `user.id`, `amount`, etc.
        

Logs will still show up in the container output (`docker compose logs -f`).

------

## Add correlation between services using W3C trace context in Kafka message headers


**Kafka-based event-driven system** so that **traces correlate across microservices** (Order ‚Üí Payment) using **W3C Trace Context** headers.

This enables full **distributed tracing** in Jaeger ‚Äî you‚Äôll see the _Order Service_‚Äôs `publish_order` span as the **parent** of the _Payment Service_‚Äôs `consume_order` span.

## What We‚Äôll Do

| Step | Description                                                                                 |
| ---- | ------------------------------------------------------------------------------------------- |
| 1Ô∏è  | Inject W3C trace context (trace ID, span ID) into Kafka message headers in the **producer** |
| 2Ô∏è  | Extract that context from Kafka headers in the **consumer**                                 |
| 3Ô∏è  | Continue the trace (propagation) so both services share the same trace in Jaeger            |


We‚Äôll use OpenTelemetry‚Äôs **propagators**:

-   `TraceContextTextMapPropagator` (W3C standard)
    
-   `inject()` / `extract()` methods to pass trace context via Kafka headers


## 1Ô∏è. Update Order Service (Producer)

In `producer/app.py`, modify the message publish logic to **inject** the trace context into Kafka headers.

Add this import:

```python
from opentelemetry.trace.propagation.tracecontext import TraceContextTextMapPropagator
``` 

Then modify the part where we publish the event:

```python
from opentelemetry.trace.propagation.tracecontext import TraceContextTextMapPropagator

propagator = TraceContextTextMapPropagator()
``` 

Inside your loop, replace the inner `with tracer.start_as_current_span("publish_order"):` block with this version:

``` python
with tracer.start_as_current_span("publish_order") as span:
    span.set_attribute("messaging.system", "kafka")
    span.set_attribute("messaging.destination", ORDERS_TOPIC)
    span.set_attribute("order.id", event["order_id"])
    span.set_attribute("user.id", event["user_id"])
    span.set_attribute("amount", event["amount"])

    # --- Inject W3C Trace Context into Kafka headers ---
    carrier = {}
    propagator.inject(carrier)
    kafka_headers = [(k, v.encode("utf-8")) for k, v in carrier.items()]

    key = event["order_id"].encode("utf-8")
    value = json.dumps(event).encode("utf-8")

    try:
        producer.produce(
            topic=ORDERS_TOPIC,
            key=key,
            value=value,
            headers=kafka_headers,  # inject trace headers
            on_delivery=delivery_report,
        )
        logger.info(
            "Order event produced",
            extra={
                "order_id": event["order_id"],
                "trace_id": span.get_span_context().trace_id,
            },
        )
    except BufferError as e:
        logger.warning("Local producer queue full; flushing", extra={"error": str(e)})
        producer.flush()

```


Now every Kafka message has headers like:

```ini
traceparent=00-<trace_id>-<span_id>-01
``` 

These follow the [W3C Trace Context standard](https://www.w3.org/TR/trace-context/).


## 2Ô∏è. Update Payment Service (Consumer)

In `consumer/app.py`, we‚Äôll **extract** that context from Kafka headers and continue the trace.

Add this import near the top:

``` python
from opentelemetry.trace.propagation.tracecontext import TraceContextTextMapPropagator
``` 

Then, before the `with tracer.start_as_current_span("consume_order")` block, extract the context:

Replace this section inside your loop:

``` python
# span around "consume + process"
with tracer.start_as_current_span("consume_order") as span:
``` 

with this:

``` python

propagator = TraceContextTextMapPropagator()

# Extract trace context from Kafka headers
carrier = {}
if msg.headers():
    for k, v in msg.headers():
        if isinstance(v, bytes):
            carrier[k] = v.decode("utf-8")
        else:
            carrier[k] = v

context = propagator.extract(carrier)

# Continue trace context
with tracer.start_as_current_span("consume_order", context=context) as span:

```

> This ensures that if `Order Service` publishes an event, the `Payment Service` span will share the same trace ID.

## 3Ô∏è. Optional: Log Trace IDs

To make debugging easier, include trace and span IDs in logs.

Add this utility:

``` python

def get_trace_context():
    span = trace.get_current_span()
    ctx = span.get_span_context()
    if ctx.trace_id:
        return {
            "trace_id": f"{ctx.trace_id:032x}",
            "span_id": f"{ctx.span_id:016x}",
        }
    return {}
```

Then use it in logs, e.g.:

``` python
logger.info(
    "Processing payment",
    extra={**get_trace_context(), "order_id": event["order_id"]},
)

```


## 4Ô∏è. Run It All

`docker compose up --build` 

Then open **Jaeger UI**:

üîó `http://localhost:16686`

### You‚Äôll see:

-   A trace with both:
    
    -   `order-service` ‚Üí `publish_order`
        
    -   `payment-service` ‚Üí `consume_order`
        
-   The same `trace_id` across both spans
    

----------

## 5Ô∏è. Example Trace Flow

``` css
Order Service (Span A)
  ‚îî‚îÄ‚îÄ publish_order
       ‚Ü≥ inject trace headers into Kafka message
            ‚Üì
Payment Service (Span B)
  ‚îî‚îÄ‚îÄ consume_order (child span)
       ‚Ü≥ extract headers ‚Üí continue same trace_id
```

So the trace graph in Jaeger shows one end-to-end flow:

``` css
Order Service ‚Üí Kafka ‚Üí Payment Service
```

## Result: Full Distributed Observability

| Capability      | Achieved by                                    |
| --------------- | ---------------------------------------------- |
| **Tracing**     | OpenTelemetry + Jaeger                         |
| **Metrics**     | (can add Prometheus exporter next)             |
| **Logging**     | Structured JSON logs with trace IDs            |
| **Correlation** | W3C Trace Context propagation in Kafka headers |
| **Resilience**  | Retries + DLQ                                  |
| **Scalability** | Kafka consumer groups                          |

-----


## **production-grade observability stack**: 

**Traces (Jaeger) + Metrics (Prometheus) + Logs (stdout / ELK)**.

Let‚Äôs integrate **OpenTelemetry Metrics** into your existing system:

-   Both microservices (`order-service`, `payment-service`) will expose metrics via **OTel SDK**
    
-   Metrics ‚Üí **OpenTelemetry Collector ‚Üí Prometheus ‚Üí Grafana**


## Overview

Here‚Äôs the data flow after adding metrics:

``` css
[Order Service]      [Payment Service]
      ‚îÇ                     ‚îÇ
      ‚îî‚îÄ‚îÄ OpenTelemetry Metrics Exporter ‚îÄ‚îÄ‚ñ∂ OTel Collector ‚îÄ‚îÄ‚ñ∂ Prometheus ‚îÄ‚îÄ‚ñ∂ Grafana
```

We‚Äôll record:

-   Event production count, latency, and failures
    
-   Message consumption count and processing latency
    
-   DLQ events
    
-   System health (exporter heartbeat)

## 1Ô∏è. Extend docker-compose.yml

Add Prometheus and Grafana, and configure OTel Collector to export metrics to Prometheus.

``` yaml

version: "3.8"

services:
  # ... existing Kafka, OTel Collector, Jaeger ...

  # Prometheus
  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
    ports:
      - "9090:9090"

  # Grafana
  grafana:
    image: grafana/grafana:latest
    depends_on:
      - prometheus
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
    volumes:
      - ./grafana/provisioning:/etc/grafana/provisioning

  order-producer:
    build: ./producer
    depends_on:
      - kafka
      - otel-collector
    environment:
      BOOTSTRAP_SERVERS: kafka:29092
      ORDERS_TOPIC: orders
      OTEL_SERVICE_NAME: order-service
      OTEL_EXPORTER_OTLP_ENDPOINT: http://otel-collector:4317
      OTEL_EXPORTER_OTLP_PROTOCOL: grpc
      OTEL_METRIC_INTERVAL: 5

  payment-consumer:
    build: ./consumer
    depends_on:
      - kafka
      - otel-collector
    environment:
      BOOTSTRAP_SERVERS: kafka:29092
      ORDERS_TOPIC: orders
      DLQ_TOPIC: orders.dlq
      GROUP_ID: payment-service
      OTEL_SERVICE_NAME: payment-service
      OTEL_EXPORTER_OTLP_ENDPOINT: http://otel-collector:4317
      OTEL_EXPORTER_OTLP_PROTOCOL: grpc
      OTEL_METRIC_INTERVAL: 5
```

## 2Ô∏è. Update otel-collector-config.yml

Add a metrics pipeline (Prometheus exporter).

``` yaml
receivers:
  otlp:
    protocols:
      grpc:
      http:

exporters:
  jaeger:
    endpoint: jaeger:14250
    tls:
      insecure: true
  prometheus:
    endpoint: "0.0.0.0:9464"  # where Prometheus will scrape metrics

processors:
  batch:

service:
  pipelines:
    traces:
      receivers: [otlp]
      processors: [batch]
      exporters: [jaeger]
    metrics:
      receivers: [otlp]
      processors: [batch]
      exporters: [prometheus]

```

## 3Ô∏è. Add prometheus.yml

``` yaml
global:
  scrape_interval: 10s

scrape_configs:
  - job_name: "otel-collector"
    static_configs:
      - targets: ["otel-collector:9464"]

```

> Prometheus scrapes the OTel Collector metrics endpoint every 10s.

## 4Ô∏è. Add Grafana datasource & dashboard provisioning (optional)
grafana/provisioning/datasources/datasource.yml

```yaml
apiVersion: 1
datasources:
  - name: Prometheus
    type: prometheus
    access: proxy
    url: http://prometheus:9090
    isDefault: true
```

You can add dashboards manually via the UI at http://localhost:3000
(Login: admin / admin)

## 5Ô∏è. Update Python Services to Record Metrics

Both services will use:

``` bash
  pip install opentelemetry-sdk opentelemetry-api opentelemetry-exporter-otlp
```

### Add to producer/app.py

Below your tracing setup, add metric instruments.

``` python
from opentelemetry.sdk.metrics import MeterProvider
from opentelemetry.metrics import get_meter
from opentelemetry.sdk.metrics.export import PeriodicExportingMetricReader
from opentelemetry.exporter.otlp.proto.grpc.metric_exporter import OTLPMetricExporter

# Metric setup
metric_exporter = OTLPMetricExporter(endpoint=OTEL_EXPORTER_OTLP_ENDPOINT, insecure=True)
reader = PeriodicExportingMetricReader(metric_exporter)
meter_provider = MeterProvider(resource=resource, metric_readers=[reader])
meter = get_meter(__name__)

# Instruments
orders_counter = meter.create_counter(
    "orders_published_total",
    unit="1",
    description="Number of order events produced",
)
orders_failed = meter.create_counter(
    "orders_failed_total",
    unit="1",
    description="Number of failed order events",
)
publish_duration = meter.create_histogram(
    "order_publish_latency_ms",
    unit="ms",
    description="Latency of producing an order event",
)

```

Then wrap your producer.produce(...) inside timing logic:

``` python
import time

start_time = time.perf_counter()
try:
    producer.produce(topic=ORDERS_TOPIC, key=key, value=value, headers=kafka_headers)
    duration = (time.perf_counter() - start_time) * 1000
    publish_duration.record(duration)
    orders_counter.add(1)
except BufferError as e:
    orders_failed.add(1)
    logger.warning("Queue full; flushing", extra={"error": str(e)})
    producer.flush()

```

### Add to consumer/app.py

Similar setup for consumption metrics:

``` python
from opentelemetry.sdk.metrics import MeterProvider
from opentelemetry.metrics import get_meter
from opentelemetry.sdk.metrics.export import PeriodicExportingMetricReader
from opentelemetry.exporter.otlp.proto.grpc.metric_exporter import OTLPMetricExporter

metric_exporter = OTLPMetricExporter(endpoint=OTEL_EXPORTER_OTLP_ENDPOINT, insecure=True)
reader = PeriodicExportingMetricReader(metric_exporter)
meter_provider = MeterProvider(resource=resource, metric_readers=[reader])
meter = get_meter(__name__)

# Instruments
messages_consumed = meter.create_counter(
    "messages_consumed_total",
    unit="1",
    description="Number of order events consumed",
)
processing_latency = meter.create_histogram(
    "payment_processing_latency_ms",
    unit="ms",
    description="Latency of payment processing",
)
failed_messages = meter.create_counter(
    "messages_failed_total",
    unit="1",
    description="Number of payment processing failures",
)
dlq_messages = meter.create_counter(
    "dlq_messages_total",
    unit="1",
    description="Number of messages sent to DLQ",
)
```

### Then update your consumer loop:

``` python
start_time = time.perf_counter()
try:
    process_payment(event)
    duration = (time.perf_counter() - start_time) * 1000
    processing_latency.record(duration)
    messages_consumed.add(1)
    consumer.commit(message=msg)
except Exception as e:
    failed_messages.add(1)
    # existing retry logic...
```

And when you send to DLQ:

``` python
dlq_messages.add(1)
```

## 6Ô∏è. Run Everything

```
docker compose up --build
```

-   **Jaeger UI:** http://localhost:16686
    
-   **Prometheus UI:** http://localhost:9090
    
-   **Grafana UI:** http://localhost:3000

## 7Ô∏è. Example PromQL Metrics (in Prometheus or Grafana)

| Metric                          | Description                     | Query                                                                              |
| ------------------------------- | ------------------------------- | ---------------------------------------------------------------------------------- |
| `orders_published_total`        | Count of order events produced  | `sum(orders_published_total)`                                                      |
| `order_publish_latency_ms`      | Publish latency histogram       | `histogram_quantile(0.95, sum(rate(order_publish_latency_ms_bucket[5m])) by (le))` |
| `messages_consumed_total`       | Count of processed order events | `rate(messages_consumed_total[1m])`                                                |
| `payment_processing_latency_ms` | Processing latency histogram    | same as above                                                                      |
| `messages_failed_total`         | Total failed events             | `sum(messages_failed_total)`                                                       |
| `dlq_messages_total`            | Total messages sent to DLQ      | `sum(dlq_messages_total)`                                                          |

## Final Architecture (Production-Grade)

```
                   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                   ‚îÇ      Order Service (Python)  ‚îÇ
                   ‚îÇ   ‚îÄ‚îÄ Traces + Metrics + Logs ‚îÇ
                   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                 ‚îÇ
                             (Kafka)
                                 ‚îÇ
                   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                   ‚îÇ    Payment Service (Python)  ‚îÇ
                   ‚îÇ   ‚îÄ‚îÄ Traces + Metrics + Logs ‚îÇ
                   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                 ‚îÇ
                         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                         ‚îÇ OTel Collector ‚îÇ
                         ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
                         ‚îÇ  ‚Üí Jaeger (traces)
                         ‚îÇ  ‚Üí Prometheus (metrics)
                         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                 ‚îÇ
                        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                        ‚îÇ   Grafana UI    ‚îÇ
                        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

```

-----

# ready-to-import Grafana Dashboard JSON

visualizes your OpenTelemetry ‚Üí Prometheus metrics from the **Order** and **Payment** services.

This dashboard shows:

-  **Throughput** (orders published / consumed)
    
-  **Latency** (publish + payment processing)
    
-  **Failures** (failed messages, DLQ rate)
    
-  **System overview panels**
    

----------

## How to Use

1.  Open Grafana ‚Üí `http://localhost:3000` (user/pass: `admin / admin`)
    
2.  Go to **Dashboards ‚Üí New ‚Üí Import**
    
3.  Paste the JSON below
    
4.  Select your **Prometheus** data source
    

----------

## Grafana Dashboard JSON

``` 
{
  "id": null,
  "uid": "kafka-event-observability",
  "title": "Kafka Event-Driven Observability",
  "tags": ["OpenTelemetry", "Kafka", "Python", "Observability"],
  "timezone": "browser",
  "schemaVersion": 39,
  "version": 1,
  "refresh": "5s",
  "panels": [
    {
      "type": "row",
      "title": "üì¶ Order Service Metrics",
      "collapsed": false,
      "gridPos": {"h": 1, "w": 24, "x": 0, "y": 0}
    },
    {
      "type": "stat",
      "title": "Orders Published / sec",
      "targets": [
        {
          "expr": "rate(orders_published_total[1m])",
          "legendFormat": "Orders Published",
          "refId": "A"
        }
      ],
      "gridPos": {"h": 4, "w": 8, "x": 0, "y": 1},
      "options": {"reduceOptions": {"calcs": ["lastNotNull"]}}
    },
    {
      "type": "stat",
      "title": "Order Publish Failures / sec",
      "targets": [
        {
          "expr": "rate(orders_failed_total[1m])",
          "legendFormat": "Failed Orders",
          "refId": "A"
        }
      ],
      "gridPos": {"h": 4, "w": 8, "x": 8, "y": 1},
      "options": {"reduceOptions": {"calcs": ["lastNotNull"]}}
    },
    {
      "type": "timeseries",
      "title": "Order Publish Latency (p95)",
      "targets": [
        {
          "expr": "histogram_quantile(0.95, sum(rate(order_publish_latency_ms_bucket[5m])) by (le))",
          "legendFormat": "p95 latency (ms)",
          "refId": "A"
        }
      ],
      "gridPos": {"h": 6, "w": 8, "x": 16, "y": 1},
      "fieldConfig": {"defaults": {"unit": "milliseconds"}}
    },
    {
      "type": "row",
      "title": "üí∞ Payment Service Metrics",
      "collapsed": false,
      "gridPos": {"h": 1, "w": 24, "x": 0, "y": 7}
    },
    {
      "type": "stat",
      "title": "Messages Consumed / sec",
      "targets": [
        {
          "expr": "rate(messages_consumed_total[1m])",
          "legendFormat": "Messages Consumed",
          "refId": "A"
        }
      ],
      "gridPos": {"h": 4, "w": 8, "x": 0, "y": 8}
    },
    {
      "type": "timeseries",
      "title": "Payment Processing Latency (p95)",
      "targets": [
        {
          "expr": "histogram_quantile(0.95, sum(rate(payment_processing_latency_ms_bucket[5m])) by (le))",
          "legendFormat": "p95 Processing Latency (ms)",
          "refId": "A"
        }
      ],
      "gridPos": {"h": 6, "w": 8, "x": 8, "y": 8},
      "fieldConfig": {"defaults": {"unit": "milliseconds"}}
    },
    {
      "type": "stat",
      "title": "Payment Failures / sec",
      "targets": [
        {
          "expr": "rate(messages_failed_total[1m])",
          "legendFormat": "Failed Payments",
          "refId": "A"
        }
      ],
      "gridPos": {"h": 4, "w": 4, "x": 16, "y": 8}
    },
    {
      "type": "stat",
      "title": "DLQ Messages / sec",
      "targets": [
        {
          "expr": "rate(dlq_messages_total[1m])",
          "legendFormat": "DLQ Rate",
          "refId": "A"
        }
      ],
      "gridPos": {"h": 4, "w": 4, "x": 20, "y": 8}
    },
    {
      "type": "row",
      "title": "üåç System Overview",
      "collapsed": false,
      "gridPos": {"h": 1, "w": 24, "x": 0, "y": 14}
    },
    {
      "type": "timeseries",
      "title": "Order vs Payment Throughput",
      "targets": [
        {
          "expr": "rate(orders_published_total[1m])",
          "legendFormat": "Orders Published",
          "refId": "A"
        },
        {
          "expr": "rate(messages_consumed_total[1m])",
          "legendFormat": "Payments Consumed",
          "refId": "B"
        }
      ],
      "gridPos": {"h": 8, "w": 12, "x": 0, "y": 15}
    },
    {
      "type": "timeseries",
      "title": "DLQ and Failed Events Over Time",
      "targets": [
        {
          "expr": "increase(dlq_messages_total[5m])",
          "legendFormat": "DLQ",
          "refId": "A"
        },
        {
          "expr": "increase(messages_failed_total[5m])",
          "legendFormat": "Failed Payments",
          "refId": "B"
        },
        {
          "expr": "increase(orders_failed_total[5m])",
          "legendFormat": "Failed Orders",
          "refId": "C"
        }
      ],
      "gridPos": {"h": 8, "w": 12, "x": 12, "y": 15}
    }
  ],
  "templating": {"list": []},
  "time": {"from": "now-15m", "to": "now"}
}

```
----------

## What You‚Äôll See in Grafana

### **Order Service**

-   ‚ÄúOrders Published / sec‚Äù ‚Üí how many orders are being emitted
    
-   ‚ÄúOrder Publish Latency (p95)‚Äù ‚Üí latency histogram (milliseconds)
    
-   ‚ÄúOrder Failures / sec‚Äù ‚Üí Kafka publish failures (network/backpressure)
    

### **Payment Service**

-   ‚ÄúMessages Consumed / sec‚Äù ‚Üí how many orders processed per second
    
-   ‚ÄúProcessing Latency (p95)‚Äù ‚Üí payment handling latency
    
-   ‚ÄúDLQ Messages / sec‚Äù ‚Üí unhealthy order events sent to DLQ
    
-   ‚ÄúPayment Failures / sec‚Äù ‚Üí retry loop exhaustion
    

### **System Overview**

-   Side-by-side throughput of both services
    
-   Error / DLQ rates for quick anomaly detection
    

----------

## Bonus Tips

1.  **Save the dashboard** under ‚ÄúKafka Observability‚Äù.
    
2.  Use Grafana‚Äôs **alerting** to send Slack/Email alerts if:
    
    -   DLQ rate > 1/min
        
    -   Latency (p95) > 200ms
        
3.  Combine this with **Jaeger trace correlation** ‚Üí you can click a trace ID in logs and inspect it in Jaeger.
    
4.  Add **Grafana Tempo** later to unify traces + metrics + logs.


------------

## let‚Äôs integrate Grafana Tempo so your system achieves ‚ÄúUnified Observability‚Äù:

metrics, logs, and traces ‚Äî all visible inside Grafana.

With Tempo, you won‚Äôt need to open Jaeger anymore ‚Äî Grafana will show traces natively, correlated with metrics and logs (e.g., click on a slow latency point ‚Üí see trace details).

## Architecture after adding Tempo

```scss
Order Service ‚Üí OpenTelemetry ‚Üí OTel Collector ‚îÄ‚îê
                                                ‚îÇ
Payment Service ‚Üí OpenTelemetry ‚Üí OTel Collector ‚îú‚îÄ‚îÄ‚ñ∫ Prometheus (metrics)
                                                ‚îú‚îÄ‚îÄ‚ñ∫ Grafana Tempo (traces)
                                                ‚îî‚îÄ‚îÄ‚ñ∫ Loki (logs, optional)
                                      ‚Üë
                                      ‚îÇ
                                   Grafana
```

## 1Ô∏è. Update docker-compose.yml

Replace Jaeger with Tempo, and link it with Grafana.

``` yaml
version: "3.8"

services:
  # Existing: zookeeper, kafka, otel-collector, prometheus

  # Tempo for distributed tracing
  tempo:
    image: grafana/tempo:latest
    container_name: tempo
    ports:
      - "3200:3200"       # Tempo HTTP API (for Grafana)
      - "4317"            # optional OTLP input (if not through collector)
    command: ["-config.file=/etc/tempo.yaml"]
    volumes:
      - ./tempo.yaml:/etc/tempo.yaml

  # Grafana
  grafana:
    image: grafana/grafana:latest
    depends_on:
      - prometheus
      - tempo
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
    volumes:
      - ./grafana/provisioning:/etc/grafana/provisioning

  # Prometheus
  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
    ports:
      - "9090:9090"

  # OTel Collector
  otel-collector:
    image: otel/opentelemetry-collector-contrib:0.110.0
    command: ["--config=/etc/otel-collector-config.yml"]
    volumes:
      - ./otel-collector-config.yml:/etc/otel-collector-config.yml
    ports:
      - "4317:4317"
      - "4318:4318"

  order-producer:
    build: ./producer
    depends_on:
      - kafka
      - otel-collector
    environment:
      BOOTSTRAP_SERVERS: kafka:29092
      ORDERS_TOPIC: orders
      OTEL_SERVICE_NAME: order-service
      OTEL_EXPORTER_OTLP_ENDPOINT: http://otel-collector:4317
      OTEL_EXPORTER_OTLP_PROTOCOL: grpc

  payment-consumer:
    build: ./consumer
    depends_on:
      - kafka
      - otel-collector
    environment:
      BOOTSTRAP_SERVERS: kafka:29092
      ORDERS_TOPIC: orders
      DLQ_TOPIC: orders.dlq
      GROUP_ID: payment-service
      OTEL_SERVICE_NAME: payment-service
      OTEL_EXPORTER_OTLP_ENDPOINT: http://otel-collector:4317
      OTEL_EXPORTER_OTLP_PROTOCOL: grpc
```

## 2Ô∏è. Add tempo.yaml

This config makes Tempo act as a trace backend for Grafana and the OpenTelemetry Collector.

``` yaml
server:
  http_listen_port: 3200

distributor:
  receivers:
    otlp:
      protocols:
        grpc:
        http:

storage:
  trace:
    backend: local
    local:
      path: /tmp/tempo
```

> Tempo is fully compatible with OTLP input (same protocol as Jaeger or the OTel Collector).

### 3. Update otel-collector-config.yml

Send traces to Tempo instead of Jaeger, and keep Prometheus for metrics.

``` yaml
receivers:
  otlp:
    protocols:
      grpc:
      http:

exporters:
  prometheus:
    endpoint: "0.0.0.0:9464"
  otlp/tempo:
    endpoint: "tempo:4317"
    tls:
      insecure: true

processors:
  batch:

service:
  pipelines:
    traces:
      receivers: [otlp]
      processors: [batch]
      exporters: [otlp/tempo]
    metrics:
      receivers: [otlp]
      processors: [batch]
      exporters: [prometheus]
```

## 4Ô∏è‚É£ Configure Grafana Data Sources

Add Prometheus and Tempo data sources.

grafana/provisioning/datasources/datasource.yml

``` yaml
apiVersion: 1
datasources:
  - name: Prometheus
    type: prometheus
    url: http://prometheus:9090
    access: proxy
    isDefault: true

  - name: Tempo
    type: tempo
    access: proxy
    url: http://tempo:3200
    jsonData:
      tracesToLogs:
        datasourceUid: prometheus
      serviceMap:
        datasourceUid: prometheus
```

This makes Grafana‚Äôs ‚ÄúExplore ‚Üí Tempo‚Äù tab active and correlates metrics ‚Üí traces.

------

## 5Ô∏è‚É£ Run the System

`docker compose up --build` 

Then open **Grafana ‚Üí http://localhost:3000**

-   üü¢ **Prometheus** is auto-detected
    
-   üü£ **Tempo** appears as the ‚ÄúTempo‚Äù trace data source
    

----------

## 6Ô∏è‚É£ View Traces in Grafana

1.  Go to **‚ÄúExplore‚Äù ‚Üí Tempo**
    
2.  Select a service (e.g., `order-service`)
    
3.  Search ‚Üí you‚Äôll see traces collected via OTel
    
4.  Click a trace to view the **span waterfall**  
    ‚Üí shows `order-service ‚Üí publish_order ‚Üí payment-service ‚Üí consume_order`
    

You can also:

-   Correlate trace data with metrics (`View in Prometheus`)
    
-   Link to logs (if Loki is added)
    
-   Overlay latency on traces

-----


## 7Ô∏è‚É£ Optional: Add Trace to Metrics Correlation

In your **Grafana Dashboard JSON**, enable trace correlation:

-   Edit any panel (e.g., _Order Publish Latency_)
    
-   Under **Field ‚Üí Data Links**, add:
    

`title:  "View Trace"  url:  "/explore?left={\"datasource\":\"Tempo\",\"queries\":[{\"query\":\"trace_id=$__value.traceID\"}]}"` 

That makes every latency point clickable ‚Üí opens its trace in Tempo UI.

-------

## Summary: Full Observability Stack

| Layer                   | Tool            | Purpose                         |
| ----------------------- | --------------- | ------------------------------- |
| **Traces**              | Grafana Tempo   | Distributed tracing             |
| **Metrics**             | Prometheus      | System & business metrics       |
| **Visualization**       | Grafana         | Unified observability dashboard |
| **Tracing pipeline**    | OTel Collector  | Ingests + exports OTLP data     |
| **Producers/Consumers** | Python OTel SDK | Emit telemetry data             |

-----


## Example Grafana Workflow

1.  Dashboard shows a spike in `order_publish_latency_ms`
    
2.  Click on the latency point ‚Üí opens Tempo trace
    
3.  See trace spans:  
    `Order Service ‚Üí Kafka ‚Üí Payment Service`
    
4.  Identify delay source (e.g., Payment retries)

----

